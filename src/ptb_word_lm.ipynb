{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorflowによるRNNの実装\n",
    "<div style=\"text-align: center;\">\n",
    "〜RNNを用いた言語モデルの学習〜\n",
    "</div>\n",
    "\n",
    "\n",
    "言語モデルとは：\n",
    "\n",
    "ある単語列が与えられたときに次にどんな単語が来るかを予測する確率モデル\n",
    "\n",
    "<img src=\"./fig/language_model.png\"　 width=\"300\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  目次\n",
    "- [目標](#目標)\n",
    "- [下準備](#下準備)\n",
    "- [言語モデルの実装](#言語モデルの実装)\n",
    "- [実行](#実行)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"目標\"></a>\n",
    "### 目標\n",
    "- RNNを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"下準備\"></a>\n",
    "### 下準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflowのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sudo pip install tensorflow-gpu==1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "save_path = './model/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータの設定\n",
    "- init_scale：重みの初期化の範囲\n",
    "- fix_epoch：学習率を固定するエポック数\n",
    "- max_epoch：エポック数\n",
    "- vocab_size：語彙数\n",
    "- learning_rate：学習率\n",
    "- hidden_size：LSTMの隠れ層の次元数\n",
    "- num_steps：LSTMに入力する文章の長さ\n",
    "- batch_size：バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_scale = 0.1\n",
    "fix_epoch = 10\n",
    "max_epoch = 20\n",
    "learning_rate = 0.1\n",
    "hidden_size = 200\n",
    "num_steps = 20\n",
    "batch_size = 20  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの読み込み\n",
    "- train_data：学習データ\n",
    "- valid_data：評価用データ\n",
    "- test_data：テストデータ\n",
    "- word_to_id：単語（キー）とid（値）の辞書\n",
    "- vocab_size：単語数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, word_to_id = tool.ptb_raw_data(data_path)\n",
    "vocab_size = len(word_to_id) #単語数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ例\n",
    "< eos > : end of sentence(文末)を表す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(' '.join(tool.ids_to_words(train_data[164:197], word_to_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"言語モデルの実装\"></a>\n",
    "### 言語モデルの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルの概要　\n",
    "<img src=\"./fig/model.png\"　 width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1：入力→分散表現\n",
    "Tensorflowで単語のIDから分散表現に直すには次の２つの関数を使用します．\n",
    "- tf.Variable\n",
    "- tf.nn.embedding_lookup\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "1-1：各行が各単語の分散表現に対応すテンソル\"embedding\"を初期化します．\n",
    "<div style=\"text-align: center;\">\n",
    "```python \n",
    "embedding = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -init_scale, init_scale))\n",
    "```\n",
    "</div>\n",
    "- 初期化には`tf.random_uniform(shape, minval, maxval)`を使います．\n",
    "    - 最小値：minval, 最大値：maxvalの連続一様分布を使ってshape：shapeのテンソルを初期化することができます．\n",
    "    - shapeは[単語の総数, LSTMの隠れ層の次元]を指定します．\n",
    "    - minvalとmaxvalにはハイパーパラメータで設定した-init_scaleとinit_scaleを代入します \n",
    "<br />\n",
    "<br />\n",
    "\n",
    "1-2：embeddingからinput_dataに対応する分散表現を求めます．\n",
    "<div style=\"text-align: center;\">\n",
    "```python\n",
    "tf.nn.embedding_lookup(embeddings, input_data)\n",
    "```\n",
    "</div>\n",
    "- `tf.nn.embedding_lookup(params, ids)`ではテンソルparamsからidsに含まれる要素を調べることができます．\n",
    "    - `tf.nn.embedding_lookup`の使用例：\n",
    "```python\n",
    ">>> params = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
    ">>> ids = tf.constant([2, 0])\n",
    ">>> word_embedding = tf.nn.embedding_lookup(params, ids)\n",
    ">>> with tf.Session() as sess:\n",
    "・・・      print(sess.run(word_embedding))\n",
    "[[7 8 9]\n",
    " [1 2 3]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2：分散表現→LSTM→LSTMの出力\n",
    "分散表現をLSTMに入力しLSTMの出力を得ます．\n",
    "\n",
    "2-1：RNNセルの初期化\n",
    "<div style=\"text-align: center;\">\n",
    "```python\n",
    "self.cell = tf.contrib.rnn.BasicLSTMCell(hidden_size)\n",
    "```\n",
    "</div>\n",
    "- Tensorflowには様々なRNNが定義されていますが，ここでは`tf.contrib.rnn.BasicLSTM`を使用します．\n",
    "- tf.contrib.rnn.BasicLSTM(num_units)でユニット数を指定します．\n",
    "\n",
    "2-2：LSTMの内部状態の初期化\n",
    "<div style=\"text-align: center;\">\n",
    "```python\n",
    "self.initial_state = cell.zeros([self.batch_size, hidden_size * 2], tf.float32)\n",
    "```\n",
    "</div>\n",
    "- LSTMは短期記憶hと長期記憶cを所持しています．（講義資料参照）\n",
    "- 短期記憶hと長期記憶cを0ベクトルで初期化します．\n",
    "\n",
    "2-3：RNNグラフの構築\n",
    "- `tf.nn.dynamic_rnn`により，2-1で定義したcellを用いてRNNを構築します．\n",
    "- `tf.nn.dynamic_rnn`の主な入力は以下のようです．\n",
    "```python\n",
    "tf.nn.dynamic_rnn(\n",
    "    cell,\n",
    "    inputs,\n",
    "    initial_state=None,\n",
    "    dtype=None\n",
    ")\n",
    "```\n",
    "- 返り値としてlstm_outputとstateを受け取ります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3：LSTMの出力→Dense Layer→予測\n",
    "LSTMの出力に線形射影を用いて予測結果を計算します．\n",
    "\n",
    "3-1：shapeの変更\n",
    "- LSTMの出力lstm_outputは[batch_size, num_steps, hidden_size]のshapeです．\n",
    "- Dense Layerの入力に適するようにtf.reshapeを用いてshapeを変更しましょう．\n",
    "\n",
    "3-2：Dense Layerの構築\n",
    "- tf.layers.denseを用いてDense Layerを構築します．\n",
    "- `tf.layers.dense`の主な入力は以下のようです．\n",
    "```python\n",
    "tf.layers.dense(\n",
    "    inputs,\n",
    "    units\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.input_data = tf.placeholder(tf.int32, [None, None])\n",
    "        batch_size = tf.shape(self.input_data)[0]\n",
    "        num_steps = tf.shape(self.input_data)[1]\n",
    "        self.target = tf.placeholder(tf.int32, [None, None])\n",
    "        \n",
    "        # TODO1：入力→分散表現\n",
    "        embedding = tf.Variable(tf.random_uniform([vocab_size, hidden_size], -init_scale, init_scale)) #初期化\n",
    "        emb_data = tf.nn.embedding_lookup(embedding, self.input_data) #分散表現に変換\n",
    "        # TODO2：分散表現→LSTM→LSTMの出力\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(hidden_size) #RNNセルの初期化\n",
    "        self.initial_state = cell.zero_state(batch_size, tf.float32) #LSTMの内部状態の初期化\n",
    "        lstm_output, state = tf.nn.dynamic_rnn(cell, emb_data, initial_state=self.initial_state, dtype=tf.float32) #RNNグラフの構築\n",
    "        # TODO3：LSTMの出力→Dense Layer→予測\n",
    "        lstm_output = tf.reshape(lstm_output, [-1, hidden_size]) #shapeの変更\n",
    "        prediction = tf.layers.dense(lstm_output, vocab_size) #Dense Layerの構築\n",
    "        \n",
    "        # sequenctial ロスを計算するために三次元テンソルに変換する\n",
    "        prediction = tf.reshape(prediction, [batch_size, num_steps, vocab_size])\n",
    "        #ロスの計算\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(prediction, self.target, \n",
    "            tf.ones([batch_size, num_steps], dtype=tf.float32),\n",
    "            average_across_timesteps=False)\n",
    "\n",
    "        # コスト（ロスの合計）を更新\n",
    "        self.output = prediction\n",
    "        self.cost = tf.reduce_sum(loss)\n",
    "        self.final_state = state\n",
    "\n",
    "        #最適化手法の設定\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行\n",
    "<a name=\"実行\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの整形とモデルの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = tool.Input(batch_size, num_steps, data=train_data)\n",
    "valid_input = tool.Input(batch_size, num_steps, data=valid_data)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1epochの挙動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(session, model, input_data, train=False, verbose=False):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "\n",
    "    fetches = {\"cost\": model.cost, \"final_state\": model.final_state,}\n",
    "    if train:\n",
    "        fetches[\"optimizer\"] = model.optimizer\n",
    "\n",
    "    for step in range(input_data.epoch_size):\n",
    "        feed_dict = {}\n",
    "        feed_dict[model.input_data], feed_dict[model.target] = input_data.next()\n",
    "        if step>0:\n",
    "            feed_dict[model.initial_state] = state\n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        cost = vals[\"cost\"]\n",
    "        state = vals[\"final_state\"]\n",
    "\n",
    "        costs += cost\n",
    "        iters += input_data.num_steps\n",
    "\n",
    "        if verbose and step % (input_data.epoch_size // 10) == 10:\n",
    "            print(\"%.3f perplexity: %.3f speed: %.0f wps\" %\n",
    "                (step * 1.0 / input_data.epoch_size, np.exp(costs / iters),\n",
    "                 iters * input_data.batch_size / (time.time() - start_time)))\n",
    "\n",
    "    return np.exp(costs / iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for i in range(max_epoch):\n",
    "        print(\"Epoch: %d\" % (i + 1))\n",
    "        train_perplexity = run_epoch(session, model, train_input, train=True, verbose=True)\n",
    "        print(\"Epoch: %d Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
    "        valid_perplexity = run_epoch(session, model, valid_input)\n",
    "        print(\"Epoch: %d Valid Perplexity: %.3f\" % (i + 1, valid_perplexity))\n",
    "\n",
    "    # モデルの保存\n",
    "    print(\"Saving model to %s\" % save_path +\"model.ckpt\")\n",
    "    saver.save(session, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テスト\n",
    "\n",
    "実際にモデルに単語を入力して，予測される続きの文を表示してみましょう．\n",
    "\n",
    "2つ下のセルにあるwordsを編集してセルを実行してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(session, model, state, test_input):\n",
    "    fetches = {\"output\": model.output, \"final_state\": model.final_state,}\n",
    "    feed_dict = {}\n",
    "    if state:\n",
    "        feed_dict[model.initial_state] = state\n",
    "    feed_dict[model.input_data] = test_input\n",
    "    vals = session.run(fetches, feed_dict)\n",
    "    prediction = vals[\"output\"]\n",
    "    state = vals[\"final_state\"]\n",
    "    prediction[0,0,1] = 0\n",
    "    return np.argmax(prediction), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = \"I am\" # これを編集\n",
    "input_words = [word_to_id[word] for word in words.lower().split(\" \") if word in word_to_id]\n",
    "gen_max = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    generate_words = []\n",
    "    saver.restore(session, save_path)\n",
    "    state=None\n",
    "    for input_ in input_words:\n",
    "        pred_word, state= generate(session, model, state, np.array([[input_]]))\n",
    "    generate_words.append(tool.ids_to_words([pred_word], word_to_id)[0])\n",
    "    for i in range(gen_max):\n",
    "        if pred_word == word_to_id[\"<eos>\"]:\n",
    "            break\n",
    "        pred_word, state = generate(session, model, state, np.array([[pred_word]]))\n",
    "        generate_words.append(tool.ids_to_words([pred_word], word_to_id)[0])\n",
    "\n",
    "print(\"prediction:\")\n",
    "print(words + \" \" + \"  \".join(generate_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
